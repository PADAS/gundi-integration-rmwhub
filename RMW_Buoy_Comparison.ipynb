{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf22912-ab83-42d5-87fb-6db79b34b93e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List\n",
    "import pytz\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import os\n",
    "import dateparser\n",
    "from erclient import ERClient\n",
    "from shapely import Point, MultiLineString\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import dotenv\n",
    "import concurrent.futures\n",
    "\n",
    "dotenv.load_dotenv(\".env\", override=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfac949-8e01-498f-9a99-b4847e09f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RmwSyncAnalyzer():\n",
    "\n",
    "    BUOY_DEV_API_KEY = os.environ.get('BUOY_DEV_API_KEY')\n",
    "    BUOY_API_KEY = os.environ.get('BUOY_API_KEY')\n",
    "    RMWHUB_API_KEY = os.environ.get('RMWHUB_API_KEY')\n",
    "    BUOY_API_URL = os.environ.get('BUOY_API_URL')\n",
    "    RMWHUB_API_SEARCH_HUB_URL = os.environ.get('RMWHUB_API_SEARCH_HUB_URL')\n",
    "    RMWHUB_API_SEARCH_OWN_URL = os.environ.get('RMWHUB_API_SEARCH_OWN_URL')\n",
    "    RMWHUB_API_HAUL_URL = os.environ.get('RMWHUB_API_HAUL_URL', 'https://ropeless.network/api/upload_deployments/')\n",
    "\n",
    "    def __init__(self, start_time: datetime):\n",
    "        self.erclient = ERClient(service_root = \"https://buoy.pamdas.org/api/v1.0\", token = RmwSyncAnalyzer.BUOY_API_KEY)\n",
    "        self.start_time = start_time\n",
    "\n",
    "        self.rmw_own_data = []\n",
    "        self.rmw_all_data = {}\n",
    "        self.er_subjects_by_name = {}\n",
    "        self.er_trap_locations = {}\n",
    "        self.rmw_active_deployments = {}\n",
    "        self.rmw_trap_locations = {}\n",
    "\n",
    "    def load_rmw_data(self):\n",
    "        body = {\n",
    "            \"api_key\": RmwSyncAnalyzer.RMWHUB_API_KEY,\n",
    "            \"format_version\": 0.1,\n",
    "            \"start_datetime_utc\": self.start_time,\n",
    "            \"max_sets\": 10000\n",
    "        }\n",
    "        \n",
    "        rmw_other_data = requests.post(RmwSyncAnalyzer.RMWHUB_API_SEARCH_HUB_URL, json=body).json()\n",
    "        self.rmw_own_data = requests.post(RmwSyncAnalyzer.RMWHUB_API_SEARCH_OWN_URL, json = body).json()\n",
    "        rmw_all_data_list = rmw_other_data['sets'] + self.rmw_own_data['sets']\n",
    "        \n",
    "        self.rmw_all_data = {}\n",
    "        for gearset in rmw_all_data_list:\n",
    "            gearset['when_updated_utc'] = dateparser.parse(gearset['when_updated_utc']).astimezone(pytz.timezone('US/Pacific')).isoformat()\n",
    "            self.rmw_all_data[gearset['set_id']] = gearset\n",
    "        \n",
    "        self._generate_deployment_sets_for_rmw_data()\n",
    "        self._generate_rmw_trap_locations()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_er_trap_id(trap_id):\n",
    "        trap_id = re.sub(r\"rmwhub_\", \"\", trap_id)\n",
    "        trap_id = re.sub(r\"edgetech_\", \"\", trap_id)\n",
    "        trap_id = re.sub(r\"device_\", \"\", trap_id)\n",
    "        return trap_id.lower()\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_rmw_trap_id(trap_id):\n",
    "        trap_id = re.sub(\"#*$\", \"\", trap_id)\n",
    "        trap_id = re.sub(\"^e_\", \"\", trap_id)\n",
    "        return trap_id.lower()\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_gearset_to_list(gearset: dict):\n",
    "        deployment = sorted(RmwSyncAnalyzer.clean_rmw_trap_id(trap['trap_id']) for trap in gearset['traps'])\n",
    "        return deployment\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_er_observation_to_list(obs: dict):\n",
    "        devices = obs['observation_details']['devices']\n",
    "        deployment = sorted(RmwSyncAnalyzer.clean_er_trap_id(device['device_id']) for device in devices)\n",
    "        return deployment\n",
    "\n",
    "    def find_rmw_deployment(self, traps: List):\n",
    "        for gearset in self.rmw_all_data.values():\n",
    "            dep = self.convert_gearset_to_list(gearset)\n",
    "            if(dep == traps):\n",
    "                return gearset\n",
    "        return None\n",
    "\n",
    "    def find_er_deployment_subjects(self, traps: List):\n",
    "        matches = []\n",
    "        for subject in self.er_subjects_by_name.values():\n",
    "            dep = RmwSyncAnalyzer.convert_er_observation_to_list(subject['last_observation'])\n",
    "            if(dep == traps):\n",
    "                matches.append(subject)\n",
    "        return matches\n",
    "                \n",
    "    def is_rmwset_active(gearset: dict):\n",
    "        for trap in gearset['traps']:\n",
    "            if(trap['status'] != 'deployed'):\n",
    "                return False\n",
    "                break\n",
    "        return True\n",
    "\n",
    "    def find_duplicate_deployments_in_rmw(self):\n",
    "        deployments = {}\n",
    "        dupes = {}\n",
    "        for set_id, deployment in self.rmw_active_deployments.items():\n",
    "            found = False\n",
    "            for test_id, test_deployment in deployments.items():\n",
    "                if(deployment == test_deployment):\n",
    "                    dupes[set_id] = test_id\n",
    "                    found = True\n",
    "                    break\n",
    "            if(not found):\n",
    "                deployments[set_id] = deployment\n",
    "        return dupes\n",
    "\n",
    "    def find_duplicate_deployed_traps_in_rmw(rmwdata):\n",
    "        traps = {}\n",
    "        for gearset in rmwdata['sets']:\n",
    "            for trap in gearset['traps']:\n",
    "                if(trap['status'] == 'deployed'):\n",
    "                    if(trap['trap_id'] in traps):\n",
    "                        traps[trap['trap_id']].append(gearset['set_id'])\n",
    "                    else:\n",
    "                        traps[trap['trap_id']] = [gearset['set_id']]\n",
    "        dupes = {}\n",
    "        for trap, sets in traps.items():\n",
    "            if(len(sets) > 1):\n",
    "                dupes[trap] = sets\n",
    "        return dupes\n",
    "\n",
    "    def find_duplicate_deployed_traps_in_er(self):\n",
    "        deployments = {}\n",
    "        for subject_name in self.er_active_deployments.keys():\n",
    "            subject = self.er_subjects_by_name[subject_name]\n",
    "            devices = subject['last_observation']['observation_details']['devices']\n",
    "            for device in devices:\n",
    "                device_id = device['device_id']\n",
    "                if(device_id in deployments):\n",
    "                    found = False\n",
    "                    for __, dep in deployments[device_id]:\n",
    "                        if(dep == devices):\n",
    "                            found = True\n",
    "                    if(not found):\n",
    "                        deployments[device_id].append((subject_name, devices))\n",
    "                else:\n",
    "                    deployments[device_id] = [(subject_name, devices)]\n",
    "        dupes = {}\n",
    "        for device_id, dev_deployments in deployments.items():\n",
    "            if(len(dev_deployments) > 1):\n",
    "                dupes[device_id] = dev_deployments\n",
    "        return dupes\n",
    "        \n",
    "    def load_er_data(self):\n",
    "        self._load_subjects_from_er()\n",
    "        self._load_latest_observations()\n",
    "        print(f\"Loaded {len(self.er_subjects_by_name)} subjects and their last observations from ER\")\n",
    "        self._generate_deployment_sets_for_er_data()\n",
    "        self._generate_er_trap_locations()\n",
    "\n",
    "    def _load_subjects_from_er(self):\n",
    "        subjects = self.erclient._get(path = \"subjects\", params = {\n",
    "            \"include_inactive\": True,\n",
    "            \"include_details\": True,\n",
    "            \"position_updated_since\": self.start_time\n",
    "        })\n",
    "        self.er_subjects_by_name = {}\n",
    "        duplicates = []\n",
    "        for trap in subjects:\n",
    "            clean = RmwSyncAnalyzer.clean_er_trap_id(trap['name'])\n",
    "            if(clean in subjects):\n",
    "                duplicates.append(clean)\n",
    "            else:\n",
    "                if(clean and trap):\n",
    "                    self.er_subjects_by_name[clean] = trap\n",
    "\n",
    "        print(f\"{len(self.er_subjects_by_name)} subjects loaded from ER.\")\n",
    "\n",
    "    def _get_latest_observation_for_subject(self, subject):\n",
    "        obs = list(self.erclient._get(\"observations\", params = {\n",
    "            \"subject_id\": subject['id'],\n",
    "            \"sort_by\": \"-recorded_at\",\n",
    "            \"include_details\": \"true\",\n",
    "            \"page_size\": 1,\n",
    "            \"include_additional_data\": True\n",
    "        })['results'])[0]\n",
    "\n",
    "        subject['created_at'] = dateparser.parse(subject['created_at']).astimezone(pytz.timezone('US/Pacific')).isoformat()\n",
    "        subject['last_observation'] = obs\n",
    "\n",
    "        return subject\n",
    "\n",
    "    def _load_latest_observations(self):\n",
    "\n",
    "        with tqdm(total=len(self.er_subjects_by_name)) as pbar:\n",
    "            subjects_with_obs = {}\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "                futures = []\n",
    "                for subject_name, subject in self.er_subjects_by_name.items():\n",
    "                    futures.append(executor.submit(self._get_latest_observation_for_subject, subject))\n",
    "                for future in concurrent.futures.as_completed(futures):\n",
    "                    result = future.result()\n",
    "                    subjects_with_obs[result['name']] = result\n",
    "                    pbar.update(1)\n",
    "        self.er_subjects_by_name = subjects_with_obs\n",
    "\n",
    "    def _generate_deployment_sets_for_er_data(self):\n",
    "\n",
    "        self.er_deployments = {}\n",
    "        self.er_active_deployments = {}\n",
    "        \n",
    "        for subject in self.er_subjects_by_name.values():\n",
    "            o = subject['last_observation']['observation_details']\n",
    "            deployment = sorted(RmwSyncAnalyzer.clean_er_trap_id(device['device_id']) for device in o['devices'])\n",
    "            self.er_deployments[subject[\"id\"]] = deployment\n",
    "        \n",
    "            if(o['event_type'] in ['gear_deployed', 'smelts_buoy_deployment', 'smelts_buoy_subsea_data']):\n",
    "                self.er_active_deployments[subject[\"name\"]] = deployment\n",
    "        print(f\"ER: {len(self.er_deployments)} deployments, {len(self.er_active_deployments)} active.\")\n",
    "\n",
    "\n",
    "    def _generate_deployment_sets_for_rmw_data(self):\n",
    "        rmw_own_deployments = {}\n",
    "        for gearset in self.rmw_own_data['sets']:\n",
    "            rmw_own_deployment = RmwSyncAnalyzer.convert_gearset_to_list(gearset)\n",
    "            dupe = False\n",
    "            for check_id, check_gearset in rmw_own_deployments.items():\n",
    "                if(check_gearset == gearset):\n",
    "                    dupe = True\n",
    "            if(not dupe):\n",
    "                rmw_own_deployments[gearset['set_id']] = rmw_own_deployment\n",
    "        \n",
    "        self.rmw_deployments = {}\n",
    "        self.rmw_active_deployments = {}\n",
    "        for gearset in self.rmw_all_data.values():\n",
    "            rmw_deployment = RmwSyncAnalyzer.convert_gearset_to_list(gearset)\n",
    "            self.rmw_deployments[gearset['set_id']] = rmw_deployment\n",
    "            if(RmwSyncAnalyzer.is_rmwset_active(gearset)):            \n",
    "                self.rmw_active_deployments[gearset['set_id']] = rmw_deployment\n",
    "        print(f\"RMW: {len(self.rmw_deployments)} deployments, {len(self.rmw_active_deployments)} active.\")\n",
    "        \n",
    "    def map_unmatched_data(rmw_all_data, er_subjects_by_name, deployed_rmw_not_deployed_er, deployed_rmw_missing_er, deployed_er_not_deployed_rmw, deployed_er_missing_rmw):\n",
    "\n",
    "        shapes = []\n",
    "        for set_id, deployment in deployed_rmw_not_deployed_er:\n",
    "            gearset = rmw_all_data[set_id]\n",
    "            shape = {'origin': 'RMW', 'set_id': set_id, 'deployment': deployment, 'lat': gearset['traps'][0]['latitude'], 'lon': gearset['traps'][0]['longitude'], 'issue': 'Deployed in RMW, retrieved in ER', 'color': 'red'}\n",
    "            points = [[trap['longitude'], trap['latitude']] for trap in gearset['traps']]\n",
    "            if(len(points) == 1):\n",
    "                shape[\"geometry\"] = Point(points[0])\n",
    "            else:\n",
    "                shape[\"geometry\"] = MultiLineString([points])\n",
    "            shapes.append(shape)\n",
    "        \n",
    "        for set_id, deployment in deployed_rmw_missing_er:\n",
    "            gearset = rmw_all_data[set_id]\n",
    "            shape = {'origin': 'RMW', 'set_id': set_id, 'deployment': deployment, 'lat': gearset['traps'][0]['latitude'], 'lon': gearset['traps'][0]['longitude'], 'issue': 'Deployed in RMW, missing from ER', 'color': 'blue'}\n",
    "            points = [[trap['longitude'], trap['latitude']] for trap in gearset['traps']]\n",
    "            if(len(points) == 1):\n",
    "                shape[\"geometry\"] = Point(points[0])\n",
    "            else:\n",
    "                shape[\"geometry\"] = MultiLineString([points])\n",
    "            shapes.append(shape)\n",
    "        \n",
    "        for trap_id, deployment in deployed_er_not_deployed_rmw:\n",
    "            devices = er_subjects_by_name[trap_id]['last_observation']['observation_details']['devices']\n",
    "            shape = {'origin': 'ER', 'subject_id': trap_id, 'deployment': deployment, 'lat': devices[0]['location']['latitude'], 'lon': devices[0]['location']['longitude'], 'issue': 'Deployed in ER, retrieved in RMW', 'color': 'yellow'}\n",
    "            points = [[device['location']['longitude'], device['location']['latitude']] for device in devices]\n",
    "            if(len(points) == 1):\n",
    "                shape[\"geometry\"] = Point(points[0])\n",
    "            else:\n",
    "                shape[\"geometry\"] = MultiLineString([points])\n",
    "            shapes.append(shape)\n",
    "        \n",
    "        for trap_id, deployment in deployed_er_missing_rmw:\n",
    "            devices = er_subjects_by_name[trap_id]['last_observation']['observation_details']['devices']\n",
    "            shape = {'origin': 'ER', 'subject_id': trap_id, 'deployment': deployment, 'lat': devices[0]['location']['latitude'], 'lon': devices[0]['location']['longitude'], 'issue': 'Deployed in ER, missing from RMW', 'color': 'green'}\n",
    "            points = [[device['location']['longitude'], device['location']['latitude']] for device in devices]\n",
    "            if(len(points) == 1):\n",
    "                shape[\"geometry\"] = Point(points[0])\n",
    "            else:\n",
    "                shape[\"geometry\"] = MultiLineString([points])\n",
    "            shapes.append(shape)\n",
    "                \n",
    "        df = pd.DataFrame.from_dict(shapes)\n",
    "        gdf = gpd.GeoDataFrame(df, geometry = df.geometry, crs=\"epsg:4326\")\n",
    "        gdf.explore(color=gdf['color'])\n",
    "\n",
    "    def _generate_rmw_trap_locations(self):\n",
    "        self.rmw_trap_locations = {}\n",
    "        for gearset_id in self.rmw_active_deployments:\n",
    "            gearset = self.rmw_all_data[gearset_id]\n",
    "            for trap in gearset['traps']:\n",
    "                self.rmw_trap_locations[RmwSyncAnalyzer.clean_rmw_trap_id(trap['trap_id'])] = (round(trap['latitude'], 5), round(trap['longitude'], 5))\n",
    "\n",
    "    def _generate_er_trap_locations(self):\n",
    "        self.er_trap_locations = {}\n",
    "        for subject_name in self.er_active_deployments.keys():\n",
    "            subject = self.er_subjects_by_name[subject_name]\n",
    "            for device in subject['last_observation']['observation_details']['devices']:\n",
    "                self.er_trap_locations[RmwSyncAnalyzer.clean_er_trap_id(device['device_id'])] = (round(device['location']['latitude'], 5), round(device['location']['longitude'], 5))\n",
    "    \n",
    "    def haul_rmw_gearset(self, gearset_id):\n",
    "    \n",
    "        gearset = self.rmw_all_data.get(gearset_id)\n",
    "        if(not gearset):\n",
    "            print(f\"Gearset {gearset} not found.\")\n",
    "            return\n",
    "\n",
    "        body = {\n",
    "            \"api_key\": RmwSyncAnalyzer.RMWHUB_API_KEY,\n",
    "            \"format_version\": 0.1,\n",
    "            \"sets\": [{\n",
    "                \"vessel_id\": gearset[\"vessel_id\"],\n",
    "                \"set_id\": gearset[\"set_id\"],\n",
    "                \"deployment_type\": \"single\" if len(gearset['traps']) == 1 else \"trawl\",\n",
    "                \"traps\": []\n",
    "            }]}\n",
    "\n",
    "        for trap in gearset['traps']:\n",
    "            trap[\"status\"] = \"retrieved\"\n",
    "            trap[\"retrieved_datetime_utc\"] = datetime.now(tz=pytz.utc).isoformat()\n",
    "            body[\"sets\"][0][\"traps\"].append(trap)\n",
    "\n",
    "        response = requests.post(RmwSyncAnalyzer.RMWHUB_API_HAUL_URL, json=body).json()\n",
    "        return response\n",
    "    \n",
    "    def haul_er_deployment(self, traps: List[str]):\n",
    "        \"\"\"Hauls an ER trap based on a trap description.  For example, to haul the deployment consisting of edgetech_123_A and edgetech_123_B, you'd pass: [\"123_A\", \"123_B\"]\n",
    "\n",
    "        Args:\n",
    "            traps (List[str]): Description of trawl to haul.\n",
    "        \"\"\"\n",
    "\n",
    "        for subject in self.find_er_deployment_subjects(traps):\n",
    "            source_obs = subject['last_observation'].copy()\n",
    "            now = datetime.now(tz = pytz.utc).isoformat()\n",
    "            obs = {'additional': {},\n",
    "                'recorded_at': now}\n",
    "            for attr in ['location', 'source', 'observation_details']:\n",
    "                obs[attr] = source_obs[attr] \n",
    "\n",
    "            obs['additional']['event_type'] = 'gear_retrieved'\n",
    "            devices = []\n",
    "            for device in obs['observation_details']['devices']:\n",
    "                device['last_retrieved'] = now\n",
    "                devices.append(device)\n",
    "            obs['additional']['devices'] = devices\n",
    "\n",
    "            print(f\"Updating {subject['name']}\")\n",
    "            self.erclient.post_observation(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d343a3b-37da-4262-8be7-1dd5de67725f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = (datetime.now(tz=pytz.utc) - timedelta(days = 1)).isoformat()\n",
    "analyzer = RmwSyncAnalyzer(start_time)\n",
    "analyzer.load_rmw_data()\n",
    "analyzer.load_er_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced3b8ff-146f-4e80-bb50-6ebd80a67d3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dupes = analyzer.find_duplicate_deployments_in_rmw()\n",
    "er_dupes = analyzer.find_duplicate_deployed_traps_in_er()\n",
    "\n",
    "deployed_rmw_not_deployed_er = []\n",
    "deployed_rmw_missing_er = []\n",
    "\n",
    "for gearset_id, deployment in analyzer.rmw_active_deployments.items():\n",
    "    if(deployment not in analyzer.er_active_deployments.values()):\n",
    "        if(deployment in analyzer.er_deployments.values()):\n",
    "            deployed_rmw_not_deployed_er.append((gearset_id, deployment))\n",
    "        else:\n",
    "            when = analyzer.rmw_all_data[gearset_id]['when_updated_utc']\n",
    "            if(dateparser.parse(when) > datetime(year = 2025, month = 1, day = 1, tzinfo=pytz.utc)):\n",
    "                deployed_rmw_missing_er.append((gearset_id, deployment))\n",
    "\n",
    "deployed_er_not_deployed_rmw = []\n",
    "deployed_er_missing_rmw = []\n",
    "for subject_name, deployment in analyzer.er_active_deployments.items():\n",
    "    if(\"rmwhub_\" in deployment[0]):\n",
    "        continue\n",
    "    if(deployment not in analyzer.rmw_active_deployments.values()):\n",
    "        if(deployment in analyzer.rmw_deployments.values()):\n",
    "            deployed_er_not_deployed_rmw.append((subject_name, deployment))\n",
    "        else:\n",
    "            deployed_er_missing_rmw.append((subject_name, deployment))\n",
    "\n",
    "different_locations = {}\n",
    "for device_id, location in analyzer.er_trap_locations.items():\n",
    "    if(device_id in analyzer.rmw_trap_locations):\n",
    "        if(location != analyzer.rmw_trap_locations[device_id]):\n",
    "            different_locations[device_id] = (location, analyzer.rmw_trap_locations[device_id])\n",
    "            \n",
    "for device_id, location in analyzer.rmw_trap_locations.items():\n",
    "    if(device_id in analyzer.er_trap_locations):\n",
    "        if(location != analyzer.er_trap_locations[device_id]):\n",
    "            different_locations[device_id] = (analyzer.er_trap_locations[device_id], location)\n",
    "\n",
    "\n",
    "print(f\"Duplicate deployments in ER ({len(er_dupes)}\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "for k, v in er_dupes.items():\n",
    "    subjects = [subj[0] for subj in v]\n",
    "    print(f\"{k} is in {len(subjects)} conflicting deployments: {', '.join(subjects)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "print(f\"Duplicate deployments in RMW ({len(dupes)}\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "if(dupes):   \n",
    "    for k, v in dupes.items():\n",
    "        print(f\"{k} is a dupe of {v}: {analyzer.rmw_active_deployments[k]}\")\n",
    "print()\n",
    "\n",
    "'''\n",
    "dupe_traps = find_duplicate_deployed_traps_in_rmw(rmw_own_data)\n",
    "print(f\"Duplicate deployed traps in RMW ({len(dupe_traps)}) [Allowed by current business logic]\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "if(dupe_traps):\n",
    "    for trap_id, sets in dupe_traps.items():\n",
    "        print(f\"Trap {trap_id} deployed in sets: {sets}\")\n",
    "print()\n",
    "'''\n",
    "\n",
    "print(f\"Deployed in RMW but not in ER ({len(deployed_rmw_not_deployed_er)})\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "if(len(deployed_rmw_not_deployed_er) > 0):\n",
    "    for missing in deployed_rmw_not_deployed_er:\n",
    "        when = analyzer.rmw_all_data[missing[0]]['when_updated_utc']\n",
    "        print(f\"Set {missing[0]} {missing[1]} at {when}\")\n",
    "print()\n",
    "\n",
    "print(f\"Deployed in RMW but missing in ER ({len(deployed_rmw_missing_er)})\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "if(len(deployed_rmw_missing_er) > 0):\n",
    "    for missing in deployed_rmw_missing_er:\n",
    "        when = analyzer.rmw_all_data[missing[0]]['when_updated_utc']\n",
    "        print(f\"Set {missing[0]} {missing[1]} at {when}\")\n",
    "print()\n",
    "\n",
    "print(f\"Deployed in ER but not deployed in RMW ({len(deployed_er_not_deployed_rmw)})\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "if(len(deployed_er_not_deployed_rmw) > 0):\n",
    "    for missing in deployed_er_not_deployed_rmw:\n",
    "        when = analyzer.find_er_deployment_subjects(missing[1])[0]['last_observation']['created_at']\n",
    "        print(f\"Subject {missing[0]} {missing[1]} at {when}\")\n",
    "print()\n",
    "\n",
    "print(f\"Deployed in ER but missing in RMW ({len(deployed_er_missing_rmw)})\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "if(len(deployed_er_missing_rmw) > 0):\n",
    "    for missing in deployed_er_missing_rmw:\n",
    "        when = analyzer.find_er_deployment_subjects(missing[1])[0]['last_observation']['created_at']\n",
    "        print(f\"Subject {missing[0]}: {missing[1]} at {when}\")\n",
    "print()\n",
    "\n",
    "print(f\"Deployed in ER and RMW but at different locations ({len(different_locations)})\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "for device, locations in different_locations.items():\n",
    "    print(f\"{device}: {locations[0]} in ER vs. {locations[1]} in RMW\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
